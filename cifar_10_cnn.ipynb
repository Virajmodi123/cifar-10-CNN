{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100  \n",
    "num_classes = 10  # Number of class for the dataset\n",
    "epochs = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data. Before we need to convert data type to float for computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices. This is called one hot encoding.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 15, 15, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1180160   \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# FLATTEN => DENSE => RELU => DROPOUT\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# a softmax classifier\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 128s 248ms/step - loss: 2.0051 - accuracy: 0.2665\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 122s 244ms/step - loss: 1.6779 - accuracy: 0.3954\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 109s 219ms/step - loss: 1.5315 - accuracy: 0.4477\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 1.4439 - accuracy: 0.4784\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 107s 214ms/step - loss: 1.3779 - accuracy: 0.5036\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 1.3206 - accuracy: 0.5287\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 104s 208ms/step - loss: 1.2755 - accuracy: 0.5469\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 104s 208ms/step - loss: 1.2309 - accuracy: 0.5629\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 103s 206ms/step - loss: 1.1880 - accuracy: 0.5803\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 104s 207ms/step - loss: 1.1490 - accuracy: 0.5940\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 1884s 4s/step - loss: 1.1110 - accuracy: 0.6098\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 112s 224ms/step - loss: 1.0764 - accuracy: 0.6205\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 100s 200ms/step - loss: 1.0487 - accuracy: 0.6318\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 100s 199ms/step - loss: 1.0172 - accuracy: 0.6442\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 99s 199ms/step - loss: 0.9887 - accuracy: 0.6537\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 100s 200ms/step - loss: 0.9643 - accuracy: 0.6626\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 101s 202ms/step - loss: 0.9384 - accuracy: 0.6690\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 102s 203ms/step - loss: 0.9210 - accuracy: 0.6785\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 100s 199ms/step - loss: 0.8990 - accuracy: 0.6865\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 102s 204ms/step - loss: 0.8830 - accuracy: 0.6930\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 99s 199ms/step - loss: 0.8629 - accuracy: 0.7002\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 99s 199ms/step - loss: 0.8482 - accuracy: 0.7045\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 99s 199ms/step - loss: 0.8261 - accuracy: 0.7099\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 99s 198ms/step - loss: 0.8083 - accuracy: 0.7209\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 99s 199ms/step - loss: 0.8008 - accuracy: 0.7220\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 99s 198ms/step - loss: 0.7815 - accuracy: 0.7263\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 107s 213ms/step - loss: 0.7741 - accuracy: 0.7286\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 119s 237ms/step - loss: 0.7563 - accuracy: 0.7368\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 0.7474 - accuracy: 0.7392\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 107s 215ms/step - loss: 0.7316 - accuracy: 0.7447\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 109s 219ms/step - loss: 0.7238 - accuracy: 0.7486\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 108s 216ms/step - loss: 0.7117 - accuracy: 0.7537\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 106s 212ms/step - loss: 0.7046 - accuracy: 0.7545\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 109s 218ms/step - loss: 0.6915 - accuracy: 0.7604\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 108s 216ms/step - loss: 0.6804 - accuracy: 0.7626\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 106s 212ms/step - loss: 0.6777 - accuracy: 0.7652\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 111s 222ms/step - loss: 0.6674 - accuracy: 0.7704\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 115s 230ms/step - loss: 0.6628 - accuracy: 0.7710\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 116s 232ms/step - loss: 0.6487 - accuracy: 0.7751\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 115s 230ms/step - loss: 0.6474 - accuracy: 0.7746\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 117s 235ms/step - loss: 0.6326 - accuracy: 0.7811\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 116s 233ms/step - loss: 0.6282 - accuracy: 0.7810\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 120s 241ms/step - loss: 0.6191 - accuracy: 0.7839\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 118s 237ms/step - loss: 0.6183 - accuracy: 0.7853\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 116s 232ms/step - loss: 0.6096 - accuracy: 0.7895\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 112s 223ms/step - loss: 0.6055 - accuracy: 0.7919\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 117s 234ms/step - loss: 0.5997 - accuracy: 0.7910\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 116s 233ms/step - loss: 0.5923 - accuracy: 0.7967\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 113s 226ms/step - loss: 0.5901 - accuracy: 0.7997\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 110s 221ms/step - loss: 0.5862 - accuracy: 0.7964\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 111s 222ms/step - loss: 0.5805 - accuracy: 0.8007\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 112s 223ms/step - loss: 0.5799 - accuracy: 0.8024\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 110s 220ms/step - loss: 0.5734 - accuracy: 0.8013\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 111s 222ms/step - loss: 0.5699 - accuracy: 0.8043\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 110s 221ms/step - loss: 0.5674 - accuracy: 0.8053\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 104s 207ms/step - loss: 0.5621 - accuracy: 0.8078\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 100s 200ms/step - loss: 0.5585 - accuracy: 0.8093\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 102s 203ms/step - loss: 0.5555 - accuracy: 0.8110\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 101s 202ms/step - loss: 0.5528 - accuracy: 0.8105\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 101s 203ms/step - loss: 0.5491 - accuracy: 0.8125\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 101s 202ms/step - loss: 0.5523 - accuracy: 0.8115\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 101s 202ms/step - loss: 0.5463 - accuracy: 0.8134\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 101s 202ms/step - loss: 0.5425 - accuracy: 0.8161\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 100s 201ms/step - loss: 0.5384 - accuracy: 0.8170\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 101s 201ms/step - loss: 0.5367 - accuracy: 0.8175\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 101s 201ms/step - loss: 0.5370 - accuracy: 0.8157\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 101s 202ms/step - loss: 0.5299 - accuracy: 0.8215\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 101s 202ms/step - loss: 0.5320 - accuracy: 0.8206\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 100s 201ms/step - loss: 0.5314 - accuracy: 0.8199\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 103s 206ms/step - loss: 0.5246 - accuracy: 0.8237\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 102s 205ms/step - loss: 0.5249 - accuracy: 0.8226\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 102s 205ms/step - loss: 0.5266 - accuracy: 0.8228\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 106s 211ms/step - loss: 0.5194 - accuracy: 0.8256\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 127s 254ms/step - loss: 0.5188 - accuracy: 0.8240\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 121s 243ms/step - loss: 0.5215 - accuracy: 0.8238\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 121s 242ms/step - loss: 0.5145 - accuracy: 0.8278\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 120s 240ms/step - loss: 0.5141 - accuracy: 0.8276\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 121s 241ms/step - loss: 0.5160 - accuracy: 0.8276\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 121s 242ms/step - loss: 0.5111 - accuracy: 0.8264\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 120s 240ms/step - loss: 0.5146 - accuracy: 0.8280\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 120s 240ms/step - loss: 0.5143 - accuracy: 0.8277\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 120s 240ms/step - loss: 0.5090 - accuracy: 0.8313\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 121s 242ms/step - loss: 0.5072 - accuracy: 0.8292\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 120s 241ms/step - loss: 0.5065 - accuracy: 0.8306\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 120s 240ms/step - loss: 0.5009 - accuracy: 0.8336\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 120s 240ms/step - loss: 0.5052 - accuracy: 0.8297\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 121s 241ms/step - loss: 0.5061 - accuracy: 0.8306\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 120s 240ms/step - loss: 0.5023 - accuracy: 0.8316\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 120s 240ms/step - loss: 0.5018 - accuracy: 0.8349\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 122s 243ms/step - loss: 0.5000 - accuracy: 0.8331\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 120s 241ms/step - loss: 0.4979 - accuracy: 0.8342\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 121s 242ms/step - loss: 0.4990 - accuracy: 0.8338\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 122s 243ms/step - loss: 0.4937 - accuracy: 0.8332\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 121s 241ms/step - loss: 0.4933 - accuracy: 0.8374\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 120s 240ms/step - loss: 0.4933 - accuracy: 0.8370\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 120s 241ms/step - loss: 0.4952 - accuracy: 0.8362\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 121s 242ms/step - loss: 0.4931 - accuracy: 0.8362\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 121s 242ms/step - loss: 0.4906 - accuracy: 0.8377\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 122s 244ms/step - loss: 0.4881 - accuracy: 0.8387\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 120s 241ms/step - loss: 0.4897 - accuracy: 0.8380\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 32ms/step - loss: 0.5955 - accuracy: 0.8063\n",
      "Test loss: 0.5955101847648621\n",
      "Test accuracy: 0.8062999844551086\n",
      "313/313 [==============================] - 7s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# make prediction.\n",
    "pred = model.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
